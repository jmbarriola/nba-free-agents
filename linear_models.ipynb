{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/jmb_ds_projects/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error, mean_absolute_percentage_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(model, dataset_type, y_pred, y_truth):\n",
    "    rmse = np.round(np.sqrt(mean_squared_error(y_truth, y_pred)), 0)\n",
    "    mae = np.round(median_absolute_error(y_truth, y_pred), 0)\n",
    "    mape = np.round(mean_absolute_percentage_error(y_truth, y_pred), 4)\n",
    "    return {'model': [model], 'dataset_type': [dataset_type], 'rmse':[rmse], 'mae': [mae], 'mape':[mape]}\n",
    "\n",
    "class PredictionEvaluation:\n",
    "    \n",
    "    def __init__(self, y_pred_train, y_truth_train, y_pred_test, y_truth_test, model_name, results_df):\n",
    "        self.y_pred_train = y_pred_train\n",
    "        self.y_truth_train = y_truth_train\n",
    "        self.y_pred_test = y_pred_test\n",
    "        self.y_truth_test = y_truth_test\n",
    "        self.model_name = model_name\n",
    "        self.results_df = results_df        \n",
    "    \n",
    "    def fill_results_df(self):\n",
    "        train_results = pd.DataFrame(evaluate_predictions(self.model_name, 'train',\n",
    "                                                          self.y_pred_train, self.y_truth_train))\n",
    "        test_results = pd.DataFrame(evaluate_predictions(self.model_name, 'test',\n",
    "                                                         self.y_pred_test, self.y_truth_test))\n",
    "        return pd.concat([self.results_df, train_results, test_results])\n",
    "\n",
    "    def diagnostics_plots(y_pred, y_truth):\n",
    "    \n",
    "        diag_plot = pd.DataFrame({'y_pred':y_pred,'y':y_truth, 'error': y_pred-y_truth})\n",
    "        diag_plot.plot.scatter(x='y',y='y_pred')\n",
    "        plt.plot([0,max(y_truth)], [0,max(y_truth)], c='black')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS_COLUMNS = [\"player\", \"position\", \"age\",\"team_id\",\"g\",\"gs\",\"mp_per_g\",\"fg_per_g\",\n",
    "\"fga_per_g\",\"fg_pct\",\"fg3_per_g\",\"fg3a_per_g\",\"fg3_pct\",\"fg2_per_g\",\"fg2a_per_g\",\n",
    "\"fg2_pct\",\"efg_pct\",\"ft_per_g\",\"fta_per_g\",\"ft_pct\",\"orb_per_g\",\"drb_per_g\",\"trb_per_g\",\n",
    "\"ast_per_g\",\"stl_per_g\",\"blk_per_g\",\"tov_per_g\",\"pf_per_g\",\"pts_per_g\"]\n",
    "NUM_STATS_COLUMNS = [col for col in STATS_COLUMNS if col not in ('\"player\", \"position\",\"team_id\"')]\n",
    "\n",
    "ADVANCED_STATS_COLUMNS =[\"player\",\"position\",\"age\",\"team_id\",\"g\",\"mp\",\"per\",\"ts_pct\",\"fg3a_per_fga_pct\",\n",
    "\"fta_per_fga_pct\",\"orb_pct\",\"drb_pct\",\"trb_pct\",\"ast_pct\",\"stl_pct\",\"blk_pct\",\"tov_pct\",\"usg_pct\",\n",
    "                         \"ows\",\"dws\",\"ws\",\"ws_per_48\",\"obpm\",\"dbpm\",\"bpm\",\"vorp\"]\n",
    "\n",
    "NUM_ADVANCED_STATS_COLUMNS = [col for col in ADVANCED_STATS_COLUMNS if col not in ('\"player\", \"position\",\"team_id\"')]\n",
    "INJURIES_COLUMNS = ['out_for_season', 'out_indefinitely','acum_out_for_season', 'acum_out_indefinitely']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/preprocessed_dataset.csv').fillna(0)\n",
    "#results_df = pd.read_csv('datasets/results/performance_metrics.csv')\n",
    "results_df = pd.DataFrame(columns=['model', 'dataset_type', 'rmse', 'mae', 'mape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols = list(set(NUM_STATS_COLUMNS + NUM_ADVANCED_STATS_COLUMNS + ['position'] + INJURIES_COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[relevant_cols+['free_agency_year']]\n",
    "y = df[['mean_salary','free_agency_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/envs/jmb_ds_projects/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X['position'] = X.position.str.split('-').apply(lambda x: x[0])\n",
    "X = pd.get_dummies(X, columns=[\"position\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = X.columns.to_list()\n",
    "x_columns.remove('free_agency_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X = X.query('free_agency_year < 2020').drop('free_agency_year', axis=1).values,\\\n",
    "                  X.query('free_agency_year == 2020').drop('free_agency_year', axis=1).values\n",
    "train_y, test_y = y.query('free_agency_year < 2020').drop('free_agency_year', axis=1).mean_salary.values,\\\n",
    "                    y.query('free_agency_year == 2020').drop('free_agency_year', axis=1).mean_salary.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_prediction = train_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_baseline = np.full((len(train_y)), baseline_prediction)\n",
    "test_y_baseline = np.full((len(test_y)), baseline_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_evaluation = PredictionEvaluation(train_y_baseline, train_y, test_y_baseline,\n",
    "                                           test_y, 'baseline', results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = baseline_evaluation.fill_results_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols = linear_model.LinearRegression(fit_intercept=True)\n",
    "ols.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = ols.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred = ols.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_evaluation = PredictionEvaluation(train_y_pred, train_y, test_y_pred,\n",
    "                                           test_y, 'modelo lineal', results_df)\n",
    "\n",
    "results_df = ols_evaluation.fill_results_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion lineal no negativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_ols = linear_model.LinearRegression(positive=True)\n",
    "nn_ols.fit(train_X, train_y)\n",
    "train_y_pred = nn_ols.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred = nn_ols.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_ols_evaluation = PredictionEvaluation(train_y_pred, train_y, test_y_pred,\n",
    "                                           test_y, 'modelo lineal no negativo', results_df)\n",
    "\n",
    "results_df = nn_ols_evaluation.fill_results_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación logaritmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_ols = linear_model.LinearRegression(fit_intercept=True)\n",
    "log_ols.fit(train_X, np.log(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = np.exp(log_ols.predict(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred = np.exp(log_ols.predict(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ols_evaluation = PredictionEvaluation(train_y_pred, train_y, test_y_pred,\n",
    "                                           test_y, 'modelo lineal logaritmo', results_df)\n",
    "\n",
    "results_df = log_ols_evaluation.fill_results_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrr}\n",
      "\\toprule\n",
      "{} &                      model & dataset\\_type &       rmse &        mae &    mape \\\\\n",
      "\\midrule\n",
      "0 &                   baseline &        train &  7046669.0 &  4191739.0 &  1.7206 \\\\\n",
      "0 &                   baseline &         test &  6136372.0 &  3988694.0 &  1.5356 \\\\\n",
      "0 &              modelo lineal &        train &  3924033.0 &  2111549.0 &  0.8302 \\\\\n",
      "0 &              modelo lineal &         test &  3559228.0 &  2088352.0 &  0.8496 \\\\\n",
      "0 &  modelo lineal no negativo &        train &  4343415.0 &  2166715.0 &  0.8812 \\\\\n",
      "0 &  modelo lineal no negativo &         test &  3798000.0 &  1817943.0 &  0.7398 \\\\\n",
      "0 &    modelo lineal logaritmo &        train &  4492837.0 &  1382346.0 &  0.5387 \\\\\n",
      "0 &    modelo lineal logaritmo &         test &  4095432.0 &  1059238.0 &  0.4941 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('datasets/results/performance_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
